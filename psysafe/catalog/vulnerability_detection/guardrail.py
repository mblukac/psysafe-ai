from enum import Enum
from typing import List, Dict, Any

from psysafe.core.prompt import PromptGuardrail
from psysafe.core.template import PromptTemplate, PromptRenderCtx
from psysafe.core.models import GuardedRequest
from psysafe.typing.requests import OpenAIChatRequest, OpenAIMessage # Assuming OpenAIChatRequest
from psysafe.catalog import GuardrailCatalog


class Sensitivity(Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"


class VulnerabilityIndicators(Enum):
    HEALTH_CONDITIONS = "health_conditions"
    LIFE_EVENTS = "life_events"
    RESILIENCE = "resilience"
    CAPABILITY = "capability"


class VulnerabilityDetectionGuardrail(PromptGuardrail[OpenAIChatRequest, Any]): # Added type hints
    """
    A guardrail to detect signs of vulnerability in user communication.
    """

    def __init__(
        self,
        indicators: List[VulnerabilityIndicators],
        sensitivity: Sensitivity,
        reasoning: bool = True,
        confidence: bool = False,
    ):
        """
        Initializes the VulnerabilityDetectionGuardrail.

        Args:
            indicators: A list of vulnerability indicators to focus on.
            sensitivity: The sensitivity level for detection.
            reasoning: Whether to include reasoning in the prompt.
            confidence: Whether to include confidence score in the prompt.
        """
        template = PromptTemplate.from_file(
            "psysafe/catalog/vulnerability_detection/prompt.md"
        )
        super().__init__(template=template)
        self.indicators = indicators
        self.sensitivity = sensitivity
        self.reasoning = reasoning
        self.confidence = confidence

    def _get_vulnerability_indicators_text(self) -> str:
        """
        Constructs the text block for vulnerability indicators.
        """
        indicator_map = {
            VulnerabilityIndicators.HEALTH_CONDITIONS: (
                "- Health conditions: This includes physical disabilities, severe or long-term illnesses, "
                "hearing or visual impairments, and mental health conditions such as depression, anxiety, "
                "or cognitive impairment."
            ),
            VulnerabilityIndicators.LIFE_EVENTS: (
                "- Recent life events: This includes events such as bereavement, job loss, relationship breakdown, "
                "or other significant personal changes that might impact stability and emotional well-being."
            ),
            VulnerabilityIndicators.RESILIENCE: (
                "- Low resilience: This refers to an individualâ€™s ability to cope with or recover from "
                "stressful situations. Low resilience might manifest as an inability to handle pressure, "
                "poor problem-solving skills, or a lack of a support network."
            ),
            VulnerabilityIndicators.CAPABILITY: (
                "- Capability issues: This includes low knowledge or confidence in managing finances, poor literacy "
                "or numeracy skills, communication difficulties (e.g., understanding complex information), "
                "or lack of digital skills."
            ),
        }
        return "\n".join(
            [indicator_map[indicator] for indicator in self.indicators]
        )

    def _get_vulnerability_sensitivity_text(self) -> str:
        """
        Constructs the text block for vulnerability sensitivity.
        """
        if self.sensitivity == Sensitivity.LOW:
            return (
                "- You will classify the user as vulnerable only if there are clear and explicit statements "
                "indicating vulnerability. Ambiguous or indirect references should not be sufficient for "
                "a 'vulnerable' classification."
            )
        elif self.sensitivity == Sensitivity.MEDIUM:
            return (
                "- You will classify the user as vulnerable if there are explicit statements or strong implicit "
                "indicators of vulnerability. You should consider the context and look for patterns that suggest "
                "vulnerability, even if not overtly stated."
            )
        elif self.sensitivity == Sensitivity.HIGH:
            return (
                "- You will classify the user as vulnerable if there are any explicit or implicit indicators, "
                "even if subtle. You should err on the side of caution and flag potential vulnerability if there "
                "is any doubt. Prioritize safety and potential risk over precision."
            )
        return "" # Should not happen

    def apply(self, request: OpenAIChatRequest) -> GuardedRequest[OpenAIChatRequest]:
        """
        Applies the guardrail to an incoming request.

        Args:
            request: The incoming OpenAIChatRequest.

        Returns:
            A GuardedRequest object containing the original and modified request.
        """
        user_messages_content: List[str] = []
        messages = request.get("messages", [])
        for msg in messages:
            if msg.get("role") == "user" and isinstance(msg.get("content"), str):
                user_messages_content.append(msg["content"])
        
        user_context = "\n".join(user_messages_content)

        vulnerability_indicators_text = self._get_vulnerability_indicators_text()
        vulnerability_sensitivity_text = self._get_vulnerability_sensitivity_text()

        render_ctx = PromptRenderCtx(
            driver_type=request.get("driver_type", "openai"),
            model_name=request.get("model", "unknown"),
            request_type="chat",
            variables={
                "user_context": user_context,
                "vulnerability_indicators_text": vulnerability_indicators_text,
                "vulnerability_sensitivity_text": vulnerability_sensitivity_text,
                "reasoning": self.reasoning,
                "confidence": self.confidence,
            }
        )

        rendered_prompt = self.template.render(render_ctx)

        modified_request = request.copy() # Ensure we don't modify the original in place if it's mutable
        
        # Ensure 'messages' key exists and is a list
        if "messages" not in modified_request or not isinstance(modified_request.get("messages"), list):
            modified_request["messages"] = []

        modified_request["messages"].insert(
            0, {"role": "system", "content": rendered_prompt}
        )
        
        # Create metadata for GuardedRequest
        # This is a placeholder; actual metadata might be more complex
        metadata: Dict[str, Any] = {
            "guardrail_name": "VulnerabilityDetectionGuardrail",
            "applied_prompt": rendered_prompt,
            "indicators_used": [ind.value for ind in self.indicators],
            "sensitivity_level": self.sensitivity.value,
            "reasoning_enabled": self.reasoning,
            "confidence_enabled": self.confidence,
        }

        return GuardedRequest(
            original_request=request,
            modified_request=modified_request,
            is_modified=True,
            metadata=metadata,
        )

# Register the guardrail with the catalog
GuardrailCatalog.register("vulnerability_detection", VulnerabilityDetectionGuardrail)