# tests/catalog/test_vulnerability_guardrail.py
import pytest
from unittest.mock import patch, MagicMock

from psysafe.catalog.vulnerability_detection.guardrail import (
    VulnerabilityDetectionGuardrail,
    Sensitivity,
    VulnerabilityIndicators
)
from psysafe.core.template import PromptTemplate
from psysafe.typing.requests import OpenAIChatRequest, OpenAIMessage

@pytest.mark.parametrize("sensitivity", list(Sensitivity))
@pytest.mark.parametrize("indicators", list(VulnerabilityIndicators))
@pytest.mark.parametrize("reasoning", [True, False])
@pytest.mark.parametrize("confidence", [True, False])
def test_vulnerability_detection_guardrail_initialization(
    sensitivity, indicators, reasoning, confidence
):
    """
    Tests initialization of VulnerabilityDetectionGuardrail with all
    valid combinations of Sensitivity, VulnerabilityIndicators, reasoning, and confidence.
    """
    guardrail = VulnerabilityDetectionGuardrail(
        sensitivity=sensitivity,
        indicators=[indicators], # Expects a list
        reasoning=reasoning,
        confidence=confidence
    )
    assert guardrail.sensitivity == sensitivity
    assert guardrail.indicators == [indicators]
    assert guardrail.reasoning == reasoning
    assert guardrail.confidence == confidence
    assert isinstance(guardrail.template, PromptTemplate)

def test_vulnerability_detection_guardrail_initialization_default_flags():
    """Tests initialization with default reasoning and confidence flags."""
    guardrail = VulnerabilityDetectionGuardrail(
        sensitivity=Sensitivity.LOW,
        indicators=[VulnerabilityIndicators.HEALTH_CONDITIONS] # Changed to a valid one from the guardrail
    )
    assert guardrail.reasoning is True # Default in guardrail is True
    assert guardrail.confidence is False # Default in guardrail is False

def test_vulnerability_detection_guardrail_initialization_multiple_indicators():
    """Tests initialization with multiple vulnerability indicators."""
    indicators = [
        VulnerabilityIndicators.LIFE_EVENTS, # Changed to valid ones
        VulnerabilityIndicators.HEALTH_CONDITIONS
    ]
    guardrail = VulnerabilityDetectionGuardrail(
        sensitivity=Sensitivity.HIGH,
        indicators=indicators
    )
    assert guardrail.indicators == indicators

# More tests for apply method and helpers will be added below.
@patch("psysafe.catalog.vulnerability_detection.guardrail.PromptTemplate.from_file")
def test_vulnerability_detection_guardrail_apply_method(mock_from_file, mocker):
    """Tests the apply method of VulnerabilityDetectionGuardrail."""
    mock_template_instance = MagicMock(spec=PromptTemplate)
    mock_render_output = "Rendered Vulnerability Prompt"
    mock_template_instance.render.return_value = mock_render_output
    mock_from_file.return_value = mock_template_instance

    guardrail = VulnerabilityDetectionGuardrail(
        sensitivity=Sensitivity.MEDIUM,
        indicators=[VulnerabilityIndicators.LIFE_EVENTS], # Changed to a valid one
        reasoning=True,
        confidence=True
    )

    original_request: OpenAIChatRequest = { # type: ignore
        "messages": [
            {"role": "system", "content": "Initial system message."},
            {"role": "user", "content": "User says something."},
        ],
        "model": "test-model",
        "driver_type": "openai"
    }
    # Make a deep copy for comparison if needed, though here we check modification
    # request_to_modify = original_request.model_copy(deep=True)

    modified_request = guardrail.apply(original_request)

    mock_from_file.assert_called_once_with(
        "psysafe/catalog/vulnerability_detection/prompt.md"
    )

    # Assert render was called with the correct context
    # We need to check the PromptRenderCtx contents
    # The actual PromptRenderCtx object is created inside the apply method,
    # so we inspect the call_args of the mock_template_instance.render
    assert mock_template_instance.render.call_count == 1
    render_call_args = mock_template_instance.render.call_args
    assert render_call_args is not None
    render_ctx = render_call_args[0][0] # First positional argument

    assert render_ctx.variables["user_context"] == "User says something."
    # The text is now constructed directly in the guardrail
    assert "Recent life events:" in render_ctx.variables["vulnerability_indicators_text"]
    assert "strong implicit indicators" in render_ctx.variables["vulnerability_sensitivity_text"]
    assert render_ctx.variables["reasoning"] is True
    assert render_ctx.variables["confidence"] is True

    # Verify the structure of the modified_request
    # The guardrail prepends the new system message
    assert len(modified_request.modified_request["messages"]) == 3
    assert modified_request.modified_request["messages"][0].get("role") == "system"
    assert modified_request.modified_request["messages"][0].get("content") == mock_render_output
    assert modified_request.modified_request["messages"][1].get("role") == "system"
    assert modified_request.modified_request["messages"][1].get("content") == "Initial system message."
    assert modified_request.modified_request["messages"][2].get("role") == "user"
    assert modified_request.modified_request["messages"][2].get("content") == "User says something."

@patch("psysafe.catalog.vulnerability_detection.guardrail.PromptTemplate.from_file")
def test_vulnerability_detection_guardrail_apply_no_initial_system_message(mock_from_file, mocker):
    """Tests apply when the original request has no system message."""
    mock_template_instance = MagicMock(spec=PromptTemplate)
    mock_render_output = "Rendered Vulnerability Prompt No System"
    mock_template_instance.render.return_value = mock_render_output
    mock_from_file.return_value = mock_template_instance

    guardrail = VulnerabilityDetectionGuardrail(
        sensitivity=Sensitivity.LOW,
        indicators=[VulnerabilityIndicators.RESILIENCE] # Changed to a valid one
    )

    original_request: OpenAIChatRequest = { # type: ignore
        "messages": [{"role": "user", "content": "Just a user message."}],
        "model": "test-model",
        "driver_type": "openai"
    }
    modified_request = guardrail.apply(original_request)

    mock_from_file.assert_called_once_with(
        "psysafe/catalog/vulnerability_detection/prompt.md"
    )
    mock_template_instance.render.assert_called_once()
    render_ctx = mock_template_instance.render.call_args[0][0]
    assert render_ctx.variables["user_context"] == "Just a user message."

    assert len(modified_request.modified_request["messages"]) == 2
    assert modified_request.modified_request["messages"][0].get("role") == "system"
    assert modified_request.modified_request["messages"][0].get("content") == mock_render_output
    assert modified_request.modified_request["messages"][1].get("role") == "user"
    assert modified_request.modified_request["messages"][1].get("content") == "Just a user message."

def test_get_vulnerability_indicators_text():
    """Tests the _get_vulnerability_indicators_text helper method."""
    guardrail = VulnerabilityDetectionGuardrail(
        sensitivity=Sensitivity.LOW, # Not used by this helper directly
        indicators=[
            VulnerabilityIndicators.LIFE_EVENTS,
            VulnerabilityIndicators.HEALTH_CONDITIONS
        ]
    )
    text = guardrail._get_vulnerability_indicators_text()
    assert "Recent life events:" in text
    assert "Health conditions:" in text

def test_get_vulnerability_indicators_text_empty():
    """Tests _get_vulnerability_indicators_text with no indicators."""
    guardrail = VulnerabilityDetectionGuardrail(
        sensitivity=Sensitivity.LOW,
        indicators=[] # Empty list
    )
    text = guardrail._get_vulnerability_indicators_text()
    assert text == "" # Empty string if no indicators

def test_get_vulnerability_sensitivity_text():
    """Tests the _get_vulnerability_sensitivity_text helper method."""
    guardrail_low = VulnerabilityDetectionGuardrail(sensitivity=Sensitivity.LOW, indicators=[])
    text_low = guardrail_low._get_vulnerability_sensitivity_text()
    assert "clear and explicit statements" in text_low

    guardrail_medium = VulnerabilityDetectionGuardrail(sensitivity=Sensitivity.MEDIUM, indicators=[])
    text_medium = guardrail_medium._get_vulnerability_sensitivity_text()
    assert "strong implicit indicators" in text_medium

    guardrail_high = VulnerabilityDetectionGuardrail(sensitivity=Sensitivity.HIGH, indicators=[])
    text_high = guardrail_high._get_vulnerability_sensitivity_text()
    assert "even if subtle" in text_high